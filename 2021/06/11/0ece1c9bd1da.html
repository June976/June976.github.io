<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/favicon/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/favicon/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><link rel="apple-touch-icon" href="/images/favicon/apple-touch-icon.png?v=2.6.2" sizes="180x180"><link rel="mask-icon" href="/images/favicon/safari_pinned_tab.svg?v=2.6.2" color="#54bcff"><meta name="msapplication-TileImage" content="/images/favicon/mstile-150x150.png"><meta name="msapplication-TileColor" content="#000000"><meta name="google-site-verification" content="zjHtMN5bFl4jkMXnYa-Qxnv5aCHi4hiWmq19dRvW9dE"><meta name="msvalidate.01" content="3FCE749E09FA739F3F8966641CE2F104"><meta name="baidu-site-verification" content="code-qK1Gt1cc5G"><meta name="description" content="一、简介        必应是微软推出的搜索引擎，相比于百度具有广告少的显著优点，比较良心。以下为必应的网址：https:&#x2F;&#x2F;cn.bing.com&#x2F; 经常使用必应应该可以发现，其主页每天都会更新一张图片，博主发现这些图片非常符合博主的审美，希望每天能够下载收藏每张图片。幸运的是已经有人完成了这项工作，具体请看这个网站：必应每日高清壁纸(https:&#x2F;&#x2F;bing.ioliu">
<meta property="og:type" content="article">
<meta property="og:title" content="python3爬虫爬取必应每日高清壁纸">
<meta property="og:url" content="https://june976.github.io/2021/06/11/0ece1c9bd1da.html">
<meta property="og:site_name" content="Jun&#39;s Blog">
<meta property="og:description" content="一、简介        必应是微软推出的搜索引擎，相比于百度具有广告少的显著优点，比较良心。以下为必应的网址：https:&#x2F;&#x2F;cn.bing.com&#x2F; 经常使用必应应该可以发现，其主页每天都会更新一张图片，博主发现这些图片非常符合博主的审美，希望每天能够下载收藏每张图片。幸运的是已经有人完成了这项工作，具体请看这个网站：必应每日高清壁纸(https:&#x2F;&#x2F;bing.ioliu">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630211400900.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630211636772.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630205949130.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630213056138.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630213631292.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630214253938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630214416124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630214855871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630231254434.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630233638872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200630231406818.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2021-06-11T14:09:35.000Z">
<meta property="article:modified_time" content="2024-05-30T05:19:53.997Z">
<meta property="article:author" content="Jun">
<meta property="article:tag" content="python3">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200630211400900.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70"><title>python3爬虫爬取必应每日高清壁纸 | Jun's Blog</title><link ref="canonical" href="https://june976.github.io/2021/06/11/0ece1c9bd1da.html"><link rel="alternate" href="/sitemap.xml" type="application/atom+xml"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement('script');
  hm.src = 'https://hm.baidu.com/hm.js?eb65d34678c3ed9f0d7fada1c3991648';
  hm.async = true;

  if (false) {
    hm.setAttribute('data-pjax', '');
  }
  var s = document.getElementsByTagName('script')[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":8},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"carbon","highlight":"light","wordWrap":false},
  reward: true,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.1"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">Tags</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/about/"><span class="header-nav-menu-item__icon"><i class="fas fa-user"></i></span><span class="header-nav-menu-item__text">About</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="javascript:;" onclick="return false;"><span class="header-nav-menu-item__icon"><i class="fas fa-sync"></i></span><span class="header-nav-menu-item__text">Next</span></a><div class="header-nav-submenu"><div class="header-nav-submenu-item"><a class="header-nav-submenu-item__link" href="/Next/"><span class="header-nav-submenu-item__icon"><i class="fas fa-file-alt"></i></span><span class="header-nav-submenu-item__text">Doc</span></a></div><div class="header-nav-submenu-item"><a class="header-nav-submenu-item__link" href="https://next.jun997.xyz/"><span class="header-nav-submenu-item__icon"><i class="fas fa-external-link-alt"></i></span><span class="header-nav-submenu-item__text">To</span></a></div></div></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Jun's Blog</div><div class="header-banner-info__subtitle">Share knowledges, Tell stories and Show something interesting!</div></div><div class="header-banner-arrow"><div class="header-banner-arrow__icon"><i class="fas fa-angle-down"></i></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">python3爬虫爬取必应每日高清壁纸</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-06-11</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2024-05-30</span></span><span class="post-meta-item post-meta-item--visitors"><span class="post-meta-item__icon" data-popover="Visitors" data-popover-pos="up"><i class="fas fa-eye"></i></span><span class="post-meta-item__value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body">
        <h1 id="一-简介"   >
          <a href="#一-简介" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#一-简介"></a> 一、简介</h1>
      
<p><mark>必应</mark>是微软推出的搜索引擎，相比于百度具有<mark>广告少</mark>的显著优点，比较<mark>良心</mark>。以下为必应的网址：<span class="exturl"><a class="exturl__link"   href="https://cn.bing.com/" >https://cn.bing.com/</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>经常使用必应应该可以发现，其主页每天都会更新一张图片，博主发现这些图片非常符合博主的审美，希望每天能够下载收藏每张图片。幸运的是已经有人完成了这项工作，具体请看这个网站：<span class="exturl"><a class="exturl__link"   href="https://bing.ioliu.cn/" >必应每日高清壁纸</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>(<strong><span class="exturl"><a class="exturl__link"   href="https://bing.ioliu.cn/" >https://bing.ioliu.cn/</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></strong>)。</p>
<p>这个网站收录了必应每天的主页图片，并且提供<mark>直接下载</mark>（管理猿太良心了，祝愿少掉一些头发，少写一些bug🤭🤭🤭）。但是博主发现这个网站缺少一个<mark>一键全部下载功能</mark>，只能一张一张图片<mark>手动下载</mark>，如果要把所有图片都下载下来，非常麻烦，因此用<mark>python</mark>写了一个下载网站上所有图片的小爬虫，分享给大家。</p>
<span id="more"></span>

        <h1 id="二-使用的环境"   >
          <a href="#二-使用的环境" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#二-使用的环境"></a> 二、使用的环境</h1>
      
<ul>
<li><strong>python3.8.1</strong>（较新版本都可）</li>
<li><strong>requests库</strong>（需要使用pip工具下载该库）</li>
<li><strong>re库</strong>（python自带，不用下载，直接导入就行）</li>
<li><strong>bs4库</strong>（需要使用pip工具下载该库）</li>
</ul>

        <h1 id="三-网页分析"   >
          <a href="#三-网页分析" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#三-网页分析"></a> 三、网页分析</h1>
      

        <h2 id="1-分析网页每一页url形式以及总页数"   >
          <a href="#1-分析网页每一页url形式以及总页数" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#1-分析网页每一页url形式以及总页数"></a> 1、分析网页每一页url形式以及总页数</h2>
      
<p>在主页的最后可以看到有下一页的信息，如下图，<br />
<img   src="https://img-blog.csdnimg.cn/20200630211400900.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<strong>在这里可以收集到网页的<mark>最大页数信息</mark>，用以后续生成每一页的<mark>url链接</mark>。点击下一页，可以看到url变成：</strong><br />
<img src="https://img-blog.csdnimg.cn/20200630211636772.png" alt="在这里插入图片描述" /><br />
容易推理出来对于不同页面网页的url形式为：</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://bing.ioliu.cn/?p=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(page_count)</span><br></pre></td></tr></table></div></figure>

        <h2 id="2-网页重要信息收集"   >
          <a href="#2-网页重要信息收集" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#2-网页重要信息收集"></a> 2、网页重要信息收集</h2>
      
<p>打开<span class="exturl"><a class="exturl__link"   href="https://bing.ioliu.cn/" >必应每日高清壁纸</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>，鼠标悬停在任意一张图片上面可以看到出现以下信息：<br />
<img   src="https://img-blog.csdnimg.cn/20200630205949130.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<strong>这其中对于我们较为重要的信息是<mark>图片介绍信息</mark>以及<mark>网页下载按钮所对应的url链接</mark>，因为我们需要把图片介绍信息作为下载图片的文件名，这样容易预览和区分。</strong></p>

        <h2 id="3-在源码中寻找所需信息的位置"   >
          <a href="#3-在源码中寻找所需信息的位置" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#3-在源码中寻找所需信息的位置"></a> 3、在源码中寻找所需信息的位置</h2>
      
<p><strong>打开网页调试工具，打开任意一页，通过调试可以发现，每一张图片的信息主要在<mark>body标签</mark>下<mark>class属性为container的div标签</mark>中：</strong><br />
<img   src="https://img-blog.csdnimg.cn/20200630213056138.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<strong>打开div标签可以看到子节点<mark>并列</mark>存放着<mark>class属性为item的div标签</mark>，每一个子标签存放的就是每一张图片的信息。如下图：</strong><br />
<img   src="https://img-blog.csdnimg.cn/20200630213631292.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<strong>这其中<mark>description属性的div标签</mark>存放的就是关于<mark>图片的描述信息</mark>，而<mark>options属性的div</mark>标签存放的就有<mark>图片的下载链接</mark>。如下图：</strong><br />
<img   src="https://img-blog.csdnimg.cn/20200630214253938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<img   src="https://img-blog.csdnimg.cn/20200630214416124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<strong>最后我们还需要知道网页的<mark>最大页面数的标签</mark>的位置，通过调试发现位于<mark>span标签</mark>下，如图：</strong><br />
<img   src="https://img-blog.csdnimg.cn/20200630214855871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
找到了这些重要信息的位置之后，就可以开始敲代码了！</p>

        <h1 id="四-代码实现"   >
          <a href="#四-代码实现" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#四-代码实现"></a> 四、代码实现</h1>
      
<p>代码主要包括五个函数：</p>
<ul>
<li><mark>GetHtmlText(url)</mark>:根据传入的<mark>url链接</mark>发送http请求，并返回获取的数据，后面很多函数都要用到，<strong>这里为了防止被服务器检测到是爬虫，建议尽量多写一些附加信息，尽量模拟浏览器的浏览操作。</strong></li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GetHtmlText</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="comment"># 根据传入的url请求网站，并返回得到的数据</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_agent = &#123;<span class="string">&#x27;user-agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">        rspon = requests.get(url, headers = user_agent)</span><br><span class="line">        rspon.encoding = rspon.apparent_encoding</span><br><span class="line">        rspon.raise_for_status()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;网页获取失败:&#x27;</span>, rspon.status_code)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> rspon</span><br></pre></td></tr></table></div></figure>
<ul>
<li><mark>GetMaxPageCount()</mark>：<strong>根据主页信息获得网页的最大页数，利用<mark>BeautifulSoup</mark>解析网页结构。</strong></li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GetMaxPageCount</span>():</span></span><br><span class="line">    <span class="comment"># 获取主页信息，并且获取网站的最大页数</span></span><br><span class="line">    max_page_count = <span class="number">0</span></span><br><span class="line">    url = <span class="string">&#x27;https://bing.ioliu.cn/&#x27;</span></span><br><span class="line">    soup = BeautifulSoup(GetHtmlText(url).text, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    tag_page = soup.find(<span class="string">&#x27;div&#x27;</span>, &#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;page&#x27;</span>&#125;)</span><br><span class="line">    page_txt = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> tag_child <span class="keyword">in</span> tag_page.children:</span><br><span class="line">        <span class="keyword">if</span>(tag_child.name == <span class="string">&#x27;span&#x27;</span>):</span><br><span class="line">            page_txt = tag_child.string</span><br><span class="line">            match = re.search(<span class="string">r&#x27;(?&lt;=1 / )\d*&#x27;</span>, page_txt)</span><br><span class="line">            max_page_count = <span class="built_in">int</span>(match.group(<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">return</span> max_page_count</span><br></pre></td></tr></table></div></figure>
<ul>
<li><mark>SavePictureInUrl(pic_url,pic_name,pic_path)</mark>：根据传入的<mark>url链接</mark>请求并获得图片的数据，然后根据<mark>文件名</mark>和<mark>文件路径</mark>将图片数据写入到对应的文件中，<strong>这里需要注意的是图片属于二进制文件，因此要以二进制文件的方式打开和写入。</strong></li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SavePictureInUrl</span>(<span class="params">pic_url,pic_name,pic_path</span>):</span></span><br><span class="line">    <span class="comment"># 根据传入的url链接获取图片的二进制数据，并且根据传入的路径和文件名将文件写入到对应的路径中。</span></span><br><span class="line">    source = GetHtmlText(pic_url)</span><br><span class="line">    <span class="keyword">if</span> source == <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    file_name = <span class="string">&#x27;&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(pic_name)</span><br><span class="line">    file = <span class="built_in">open</span>(pic_path+file_name, <span class="string">&quot;wb&quot;</span>)    <span class="comment">#以二进制写的方式打开文件。</span></span><br><span class="line">    file.write(source.content)</span><br><span class="line">    file.close()</span><br></pre></td></tr></table></div></figure>
<ul>
<li><mark>GetOnePageJpg(page_count, pic_path)</mark>：根据当前传入的页码<mark>自动生成</mark>对应的url链接，然后请求并获得相应的数据，解析结构后获得图片的信息，<mark>拼接成文件的名称</mark>，<strong>这里要注意windows规定某些特殊字符不能用作文件名，需要加以剔除，不然会出问题</strong>。然后获取图片的下载地址并<mark>拼接成完整的url地址</mark>，将这些信息传入以上函数就能获得图片。</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GetOnePageJpg</span>(<span class="params">page_count, pic_path</span>):</span></span><br><span class="line">    <span class="comment"># 从返回的网页数据中获取每张图片的相关信息以及图片下载的url，然后调用相关函数下载图片</span></span><br><span class="line">    url = <span class="string">&#x27;https://bing.ioliu.cn/?p=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(page_count)</span><br><span class="line">    suop = BeautifulSoup(GetHtmlText(url).text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    tag_container = suop.find_all(<span class="string">&#x27;div&#x27;</span>, &#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;container&#x27;</span>&#125;)</span><br><span class="line">    tag_item = tag_container[<span class="number">1</span>]</span><br><span class="line">    url_photo = <span class="string">&#x27;https://bing.ioliu.cn&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> tag_pic <span class="keyword">in</span> tag_item.children:</span><br><span class="line">        <span class="comment"># 获取图片的标题和日期信息并且拼接成图片名</span></span><br><span class="line">        tag_title = tag_pic.find(<span class="string">&#x27;h3&#x27;</span>)</span><br><span class="line">        text_title = tag_title.string</span><br><span class="line">        a = re.findall(<span class="string">r&#x27;[^\*&quot;/:?\\|&lt;&gt;]&#x27;</span>, text_title, re.S)      <span class="comment">#剔除某些不能作为文件名的特殊字符</span></span><br><span class="line">        text_title = <span class="string">&#x27;&#x27;</span>.join(a)</span><br><span class="line">        tag_calendar = tag_pic.find(<span class="string">&#x27;p&#x27;</span>, &#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;calendar&#x27;</span>&#125;)</span><br><span class="line">        tag_em = tag_calendar.find(<span class="string">&#x27;em&#x27;</span>)</span><br><span class="line">        text_calendar = tag_em.string</span><br><span class="line">        text_pic_name = text_calendar + <span class="string">&#x27;__&#x27;</span> + text_title</span><br><span class="line">        <span class="comment"># 获取图片的下载url</span></span><br><span class="line">        tag_download = tag_pic.find(<span class="string">&#x27;a&#x27;</span>, &#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;ctrl download&#x27;</span>&#125;)</span><br><span class="line">        url_pic = url_photo + tag_download[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="comment">#信息保存到图片中</span></span><br><span class="line">        SavePictureInUrl(url_pic, text_pic_name, pic_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;.&#x27;</span>, end=<span class="string">&#x27;&#x27;</span>, flush=<span class="literal">True</span>)        <span class="comment">#输出进度信息</span></span><br></pre></td></tr></table></div></figure>
<ul>
<li><mark>GetAllPageJpg(pic_path)</mark>:传入<mark>文件的保存地址</mark>，然后获取所有网页的图片，主要是调用前面的函数。</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GetAllPageJpg</span>(<span class="params">pic_path</span>):</span></span><br><span class="line">    <span class="comment"># 爬取所有的图片，并保存在输入的路径参数下</span></span><br><span class="line">    max_page_count = GetMaxPageCount()</span><br><span class="line">    <span class="keyword">for</span> page_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, max_page_count):</span><br><span class="line">        GetOnePageJpg(page_index, pic_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\r&#x27;</span>, <span class="string">&#x27;正在获取，已完成：&#123;:.2f&#125; %&#x27;</span>.<span class="built_in">format</span>(page_index/max_page_count*<span class="number">100</span>), end = <span class="string">&#x27;&#x27;</span>, flush=<span class="literal">True</span>)      <span class="comment">#输出进度信息</span></span><br></pre></td></tr></table></div></figure>
<ul>
<li>main():最后编写和调用main函数就能完成。</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># 程序执行</span></span><br><span class="line">    pic_path = <span class="string">&#x27;E://bing图片/&#x27;</span>   <span class="comment">#文件保存路径</span></span><br><span class="line">    GetAllPageJpg(pic_path)</span><br><span class="line">main()       <span class="comment">#执行main函数</span></span><br></pre></td></tr></table></div></figure>

        <h1 id="五-运行爬虫"   >
          <a href="#五-运行爬虫" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#五-运行爬虫"></a> 五、运行爬虫</h1>
      
<p>windows运行该脚本首先win+R打开运行，然后输入cmd打开控制台，将工作文件夹切换到脚本所在文件夹，然后输入命令：</p>
<figure class="highlight powershell"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python bingjpg.py</span><br></pre></td></tr></table></div></figure>
<p>即可运行该脚本（<strong>前提是电脑已经安装好了python环境</strong>）。</p>
<p>万万没想到，这个网站居然有<strong>反爬机制</strong>？！脚本运行一段时间，下载了21.21%出现403错误🤣🤣🤣，仅仅下载了部分图片。<br />
<img   src="https://img-blog.csdnimg.cn/20200630231254434.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<img   src="https://img-blog.csdnimg.cn/20200630233638872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<strong>此时在浏览器打开网页也被禁止访问，应该是ip被禁了</strong>！！！不过目前大多数宽带都是使用<mark>DHCP服务生成动态ip</mark>，一般<mark>2个小时</mark>之后ip会自动更换，或者直接<mark>重启路由器</mark>也可以立即更换ip，更换了ip地址之后又能访问该网站。<br />
<img   src="https://img-blog.csdnimg.cn/20200630231406818.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRUTQ==,size_16,color_FFFFFF,t_70" style="width: image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,tepx;height: t_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGpx;"  alt="在这里插入图片描述" /><br />
<strong>针对这一情况推测网站很有可能是根据<mark>下载请求的速度</mark>以及<mark>数量</mark>来判断爬虫，从而封禁ip，后面可以利用前面已经写好的函数从后续页开始爬取，稍微改动代码就行，不用又从头开始。</strong></p>

        <h1 id="六-后续改进"   >
          <a href="#六-后续改进" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#六-后续改进"></a> 六、后续改进</h1>
      
<p>后续该爬虫还有两个方面可以改进：</p>
<ol>
<li><strong>爬取一次中断之后重新爬取时，之前爬取的图片又要重新爬取，费时费力，后面可以加一个判断，如果当前文件夹中已经存在该图片，就不再爬取，直接跳过。</strong></li>
<li><strong>适当降低爬取速度，每爬取一张图片之后sleep一段时间，防止被反爬程序检测到。</strong></li>
</ol>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ END ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">Author: </span><span class="copyright-author__value"><a href="https://june976.github.io">Jun</a></span></div><div class="copyright-link"><span class="copyright-link__name">Link: </span><span class="copyright-link__value"><a href="https://june976.github.io/2021/06/11/0ece1c9bd1da.html">https://june976.github.io/2021/06/11/0ece1c9bd1da.html</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">Copyright: </span><span class="copyright-notice__value">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> unless stating additionally</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://june976.github.io/tags/python3/">python3</a></span><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://june976.github.io/tags/%E7%88%AC%E8%99%AB/">爬虫</a></span></div><div class="post-share"><div class="social-share" data-sites="qzone, qq, weibo, wechat, douban, linkedin, facebook, twitter, google">Share to: </div></div><div class="post-reward reward"><div class="reward-button">￥打赏我￥</div><div class="reward-qrcode"><span class="reward-qrcode-alipay"><img class="reward-qrcode-alipay__img" src="/images/PayQRCode/alipay.jpg"><div class="reward-qrcode-alipay__text">Alipay</div></span><span class="reward-qrcode-wechat"><img class="reward-qrcode-wechat__img" src="/images/PayQRCode/wechat.png"><div class="reward-qrcode-wechat__text">Wechat</div></span></div></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2021/06/11/5004c3b447fd.html"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">matlab制作圆摆线动画</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2021/06/11/4d79dd3174ce.html"><span class="paginator-prev__text">在阿里云ECS服务器上搭建FTP服务</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">Catalog</span><span class="sidebar-nav-ov">Overview</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">
           一、简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C-%E4%BD%BF%E7%94%A8%E7%9A%84%E7%8E%AF%E5%A2%83"><span class="toc-number">2.</span> <span class="toc-text">
           二、使用的环境</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89-%E7%BD%91%E9%A1%B5%E5%88%86%E6%9E%90"><span class="toc-number">3.</span> <span class="toc-text">
           三、网页分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B5%E6%AF%8F%E4%B8%80%E9%A1%B5url%E5%BD%A2%E5%BC%8F%E4%BB%A5%E5%8F%8A%E6%80%BB%E9%A1%B5%E6%95%B0"><span class="toc-number">3.1.</span> <span class="toc-text">
           1、分析网页每一页url形式以及总页数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%BD%91%E9%A1%B5%E9%87%8D%E8%A6%81%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86"><span class="toc-number">3.2.</span> <span class="toc-text">
           2、网页重要信息收集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%9C%A8%E6%BA%90%E7%A0%81%E4%B8%AD%E5%AF%BB%E6%89%BE%E6%89%80%E9%9C%80%E4%BF%A1%E6%81%AF%E7%9A%84%E4%BD%8D%E7%BD%AE"><span class="toc-number">3.3.</span> <span class="toc-text">
           3、在源码中寻找所需信息的位置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.</span> <span class="toc-text">
           四、代码实现</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94-%E8%BF%90%E8%A1%8C%E7%88%AC%E8%99%AB"><span class="toc-number">5.</span> <span class="toc-text">
           五、运行爬虫</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD-%E5%90%8E%E7%BB%AD%E6%94%B9%E8%BF%9B"><span class="toc-number">6.</span> <span class="toc-text">
           六、后续改进</span></a></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/profile.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">A Journey of A Thousand Miles Begins with A Single Step!</p></div><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="https://github.com/June976" target="_blank" rel="noopener" data-popover="Github" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-github"></i></span></a><a class="sidebar-ov-social-item" href="https://www.google.com/" target="_blank" rel="noopener" data-popover="Google" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-google"></i></span></a><a class="sidebar-ov-social-item" href="https://weibo.com/" target="_blank" rel="noopener" data-popover="Weibo" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-weibo"></i></span></a><a class="sidebar-ov-social-item" href="https://www.zhihu.com/" target="_blank" rel="noopener" data-popover="Zhihu" data-popover-pos="up"><span class="sidebar-ov-social-item__icon">知</span></a><a class="sidebar-ov-social-item" href="https://blog.csdn.net/HelloWorldTM?type=blog" target="_blank" rel="noopener" data-popover="social.CSDN" data-popover-pos="up"><span class="sidebar-ov-social-item__icon">C</span></a><a class="sidebar-ov-social-item" href="mailto:admin@jun997.xyz" target="_blank" rel="noopener" data-popover="social.QQmail" data-popover-pos="up"><span class="sidebar-ov-social-item__icon">M</span></a></div><div class="sidebar-ov-feed"><span class="sidebar-ov-feed-email"><a class="sidebar-ov-feed-email__link" href="https://mailchi.mp/78fbe8b89a13/juns-blog-subscribe" target="_blank" rel="noopener"><span class="sidebar-ov-feed-email__icon"><i class="fas fa-envelope"></i></span><span>Email Subscribe</span></a></span><span class="sidebar-ov-feed-rss"><a class="sidebar-ov-feed-rss__link" href="/sitemap.xml" target="_blank" rel="noopener"><span class="sidebar-ov-feed-rss__icon"><i class="fas fa-rss"></i></span><span>RSS Subscribe</span></a></span></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">170</div><div class="sidebar-ov-state-item__name">Archives</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">38</div><div class="sidebar-ov-state-item__name">Tags</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">You have read </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2024</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Jun All Rights Reserved</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.4.1</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div><div class="busuanzi"><span class="busuanzi-siteuv"><span class="busuanzi-siteuv__icon" data-popover-pos="up" data-popover="Unique Visitor"><i class="fas fa-user"></i></span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_uv"></span></span><span class="busuanzi-sitepv"><span class="busuanzi-siteuv__icon" data-popover-pos="up" data-popover="Page View"><i class="fas fa-eye"></i></span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>